# Phase 1b: Media Library Explorer

> **Context:** This is an addition to the Hotel Instagram AI Pipeline. Phase 1 (intelligent media library indexer) has already indexed all hotel photos into Supabase with AI-generated tags. Phase 1b provides a visual interface to explore, verify, and test that data.
> **Timing:** End of Week 2, right after indexing is complete
> **Effort:** 1-2 days
> **Hosting:** Streamlit Cloud (free) or Railway

---

## Problem

After indexing 500+ photos, the data sits in Supabase with no way to see, verify, or manipulate it without writing SQL queries. We need a visual interface to:
1. Verify AI tagging accuracy
2. Explore the media library with filters
3. Spot content gaps (e.g. only 2 food photos vs 45 room photos)
4. Test caption generation on selected photos before the pipeline is automated
5. Correct tags when AI makes mistakes

---

## Schema Changes to `media_library`

Add these 2 fields to the existing `media_library` table:

```sql
ALTER TABLE media_library ADD COLUMN ai_description TEXT;
ALTER TABLE media_library ADD COLUMN manual_notes TEXT;
```

- `ai_description`: Generated by Claude Vision at indexing. **Never manually edited.** Represents how AI "sees" the photo. Preserved across re-indexing.
- `manual_notes`: Human context AI can't know. Examples:
  - "Favorite room for honeymooners"
  - "Photo taken during 2024 film festival"
  - "Client in photo — don't publish without consent"
  - "Balcony has been renovated since — stop using this photo"
- Both fields are sent to Claude in Phase 3 for richer caption generation.

## New Table: `tag_corrections`

```sql
CREATE TABLE tag_corrections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    media_id UUID REFERENCES media_library(id),
    field_name TEXT,        -- category, ambiance, season...
    old_value TEXT,
    new_value TEXT,
    corrected_at TIMESTAMP DEFAULT now()
);
```

Purpose: Track manual corrections to AI tags. If correction rate is high → improve the Vision analysis prompt.

---

## 5 Views

### View 1 — Stats & Gaps (Home Page)

Global overview of the media library:
- Total media count (photos vs videos)
- Distribution by category (horizontal bars): chambre, commun, destination, food, experience
- Distribution by season
- Average quality score per category
- **"Gaps Detected" block** — automatic alerts:
  - "Only 2 photos in category 'food' — recommended minimum: 15"
  - "No winter photos for category 'destination'"
  - "12 photos with quality score < 5 — consider archiving"

### View 2 — Filterable Gallery

Photo grid with sidebar filters:
- Category (multi-select dropdown)
- Subcategory (multi-select dropdown)
- Ambiance (multi-select: romantique, lumineux, intime, festif...)
- Season (multi-select: été, hiver, toute_saison...)
- Quality score minimum (slider 1-10)
- Status (available / used / archived)
- Sort by: quality desc, date added, times used asc
- Each photo thumbnail shows category tag + quality score as overlay
- Click a photo → navigates to Detail view

### View 3 — Media Detail & Tag Correction

When clicking a photo from the gallery:
- Full-size image display
- `ai_description` displayed as read-only text block
- `manual_notes` as editable text area
- All AI tags displayed as editable fields:
  - Category (dropdown)
  - Subcategory (dropdown)
  - Ambiance (multi-select)
  - Season (multi-select)
  - Elements (editable tag list)
  - Quality score (slider)
- **"Save Corrections"** button → updates `media_library` + logs changes to `tag_corrections`
- Usage history: when this photo was posted, in what context

### View 4 — Test Lab

The creative sandbox:
1. Select a photo from a mini-gallery or search
2. Choose editorial context:
   - Theme (dropdown: chambre, destination, experience, offre)
   - Season (dropdown: été, hiver, printemps, automne)
   - CTA type (dropdown: link_bio, dm, book_now)
3. Click **"Generate"**
4. Claude API call with the photo + `ai_description` + `manual_notes` + context
5. Displays in real-time:
   - 2 caption variants (short + storytelling)
   - Each in ES / EN / FR (tabs)
   - 20 hashtags (mix popularity)
6. **"Regenerate"** button for new variants
7. **"Copy"** button for each caption (for manual posting via SocialBee)

Later (Phase 3): add buttons to test Nano Banana visual variants and Veo 3 Reels from this same view.

### View 5 — Videos

Same logic as photo gallery but adapted:
- Video preview with embedded player
- Duration display
- Video-specific tags (with/without audio, interior/exterior, action/static)
- Same filtering and detail/correction capabilities

---

## File Structure

```
media_explorer/
├── app.py                  # Streamlit entry point, navigation
├── pages/
│   ├── 01_stats.py         # View 1 — Stats & Gaps
│   ├── 02_gallery.py       # View 2 — Filterable Gallery
│   ├── 03_detail.py        # View 3 — Detail & Tag Correction
│   ├── 04_lab.py           # View 4 — Test Lab (caption generation)
│   └── 05_videos.py        # View 5 — Videos
├── utils/
│   ├── supabase_client.py  # Supabase connection
│   ├── claude_client.py    # Claude API calls
│   └── filters.py          # Shared filtering logic
├── config.py               # Hotel-specific settings
└── requirements.txt
```

## Dependencies

```
streamlit
supabase
anthropic
Pillow
```

## Environment Variables

```
SUPABASE_URL=
SUPABASE_KEY=
ANTHROPIC_API_KEY=
```

---

## Caption Generation Prompt (for Test Lab)

```python
def generate_caption(media, theme, season, cta_type):
    prompt = f"""Tu es le community manager d'un 
hôtel boutique Art Nouveau à Sitges (Barcelone).

Photo : {media['elements']}
Description IA : {media['ai_description']}
Notes humaines : {media.get('manual_notes', 'Aucune')}
Catégorie : {media['category']}
Ambiance : {media['ambiance']}
Thème du jour : {theme}
Saison : {season}

Génère 2 variantes de légende Instagram :
- Version courte (2-3 lignes, punch)
- Version storytelling (5-6 lignes, émotionnelle)

Chaque variante en ES, EN, FR.
Inclus un CTA naturel ({cta_type}).
Ton : chaleureux, authentique, jamais corporate.
Inclus 20 hashtags (mix popularité)."""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2000,
        messages=[{
            "role": "user",
            "content": [
                {"type": "image", "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": encode_image(media["file_path"])
                }},
                {"type": "text", "text": prompt}
            ]
        }]
    )
    return parse_captions(response)
```

---

## Strategic Value

- **Immediate usefulness:** Daily working tool from Week 2, before the automated pipeline exists
- **Manual workflow bridge:** Find photo → generate caption in lab → copy-paste to SocialBee for manual posting
- **Quality control:** High correction rate = improve the Vision indexing prompt
- **Gap analysis:** Know exactly what photos to take next
- **Foundation for Phase 4:** The validation dashboard (Phase 4) extends this with calendar view and publish actions
